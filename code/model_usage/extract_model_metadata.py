import torch
import json
from ultralytics import YOLO
from pathlib import Path
import yaml
import os

# Ruta del modelo
model_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'models', 'pebble_seg_model.pt')

def extract_model_metadata():
    """
    Extrae toda la metadata del modelo YOLO entrenado
    """
    print("üîç Extrayendo metadata del modelo YOLO...")
    print(f"üìÅ Modelo: {model_path}")
    print("-" * 80)
    
    try:
        # Cargar el checkpoint directamente con torch
        print("‚ö° Cargando checkpoint...")
        checkpoint = torch.load(model_path, map_location='cpu')
        
        print("\nüìä INFORMACI√ìN GENERAL DEL MODELO:")
        print("=" * 50)
        
        # Informaci√≥n b√°sica del modelo
        if 'model' in checkpoint:
            print(f"‚úÖ Modelo cargado exitosamente")
            
        # Epoch informaci√≥n
        if 'epoch' in checkpoint:
            print(f"üéØ Epoch final: {checkpoint['epoch']}")
            print(f"üèÜ Este es el MEJOR modelo obtenido en el epoch: {checkpoint['epoch']}")
        
        # M√©tricas del entrenamiento
        if 'best_fitness' in checkpoint:
            best_fitness = checkpoint['best_fitness']
            if best_fitness is not None:
                print(f"üèÖ Mejor fitness: {best_fitness:.6f}")
            else:
                print(f"üèÖ Mejor fitness: No disponible (None)")
        
        # Informaci√≥n del entrenador
        if 'train_args' in checkpoint:
            print(f"\nüîß ARGUMENTOS DE ENTRENAMIENTO:")
            print("-" * 30)
            train_args = checkpoint['train_args']
            if train_args is not None:
                for key, value in train_args.items():
                    print(f"  {key}: {value}")
            else:
                print("  No disponible (None)")
        
        # Informaci√≥n del optimizador
        if 'optimizer' in checkpoint:
            print(f"\n‚öôÔ∏è OPTIMIZADOR:")
            print("-" * 20)
            optimizer_info = checkpoint['optimizer']
            if optimizer_info is not None and 'param_groups' in optimizer_info:
                for i, group in enumerate(optimizer_info['param_groups']):
                    print(f"  Grupo {i}:")
                    for key, value in group.items():
                        if key != 'params':  # Excluir par√°metros (muy largos)
                            print(f"    {key}: {value}")
            else:
                print("  No disponible")
        
        # M√©tricas detalladas si est√°n disponibles
        if 'model' in checkpoint:
            try:
                # Cargar usando ultralytics para obtener m√°s info
                model = YOLO(model_path)
                
                print(f"\nüèóÔ∏è ARQUITECTURA DEL MODELO:")
                print("-" * 30)
                print(f"  Nombre del modelo: {model.model_name if hasattr(model, 'model_name') else 'YOLOv8'}")
                print(f"  N√∫mero de clases: {model.model.nc if hasattr(model.model, 'nc') else 'N/A'}")
                print(f"  Nombres de clases: {model.names}")
                
                # Informaci√≥n del dispositivo de entrenamiento
                if hasattr(model.model, 'device'):
                    print(f"  Dispositivo de entrenamiento: {model.model.device}")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è No se pudo cargar informaci√≥n adicional del modelo: {e}")
        
        # Fecha de entrenamiento si est√° disponible
        if 'date' in checkpoint:
            date_val = checkpoint['date']
            print(f"\nüìÖ INFORMACI√ìN TEMPORAL:")
            print("-" * 25)
            if date_val is not None:
                print(f"  Fecha de entrenamiento: {date_val}")
            else:
                print(f"  Fecha de entrenamiento: No disponible")
        
        # Versi√≥n de ultralytics
        if 'version' in checkpoint:
            version_val = checkpoint['version']
            if version_val is not None:
                print(f"  Versi√≥n de Ultralytics: {version_val}")
            else:
                print(f"  Versi√≥n de Ultralytics: No disponible")
        
        # Informaci√≥n de updates/√©poca
        if 'updates' in checkpoint:
            updates_val = checkpoint['updates']
            if updates_val is not None:
                print(f"  Total de updates: {updates_val}")
            else:
                print(f"  Total de updates: No disponible")
            
        # EMA (Exponential Moving Average) info
        if 'ema' in checkpoint:
            print(f"\nüé≠ INFORMACI√ìN EMA:")
            print("-" * 20)
            ema_info = checkpoint['ema']
            if ema_info is not None:
                if hasattr(ema_info, 'updates'):
                    print(f"  EMA updates: {ema_info.updates}")
                if hasattr(ema_info, 'decay'):
                    print(f"  EMA decay: {ema_info.decay}")
            else:
                print("  EMA info no disponible")
        
        # Mostrar todas las claves disponibles en el checkpoint
        print(f"\nüîë CLAVES DISPONIBLES EN EL CHECKPOINT:")
        print("-" * 45)
        for key in checkpoint.keys():
            value = checkpoint[key]
            if value is not None:
                if isinstance(value, (int, float, str, bool)):
                    print(f"  {key}: {value}")
                else:
                    print(f"  {key}: <{type(value).__name__}>")
            else:
                print(f"  {key}: None")
        
        # Buscar archivo de resultados de entrenamiento
        model_dir = Path(model_path).parent.parent
        results_file = model_dir / 'results.csv'
        args_file = model_dir / 'args.yaml'
        
        if results_file.exists():
            print(f"\nüìà ARCHIVO DE RESULTADOS ENCONTRADO:")
            print("-" * 40)
            print(f"  üìÑ {results_file}")
            
            # Leer √∫ltimas l√≠neas del CSV para ver progreso
            try:
                with open(results_file, 'r') as f:
                    lines = f.readlines()
                    print(f"  üìä Total de epochs registrados: {len(lines) - 1}")  # -1 por header
                    if len(lines) > 1:
                        print(f"  üîö √öltima l√≠nea: {lines[-1].strip()}")
            except Exception as e:
                print(f"  ‚ö†Ô∏è Error leyendo CSV: {e}")
        
        if args_file.exists():
            print(f"\n‚öôÔ∏è ARCHIVO DE CONFIGURACI√ìN ENCONTRADO:")
            print("-" * 45)
            print(f"  üìÑ {args_file}")
            
            try:
                with open(args_file, 'r') as f:
                    args_data = yaml.safe_load(f)
                    print(f"\nüîß CONFIGURACI√ìN COMPLETA DEL ENTRENAMIENTO:")
                    print("-" * 50)
                    for key, value in args_data.items():
                        print(f"  {key}: {value}")
            except Exception as e:
                print(f"  ‚ö†Ô∏è Error leyendo YAML: {e}")
        
        # Guardar metadata en JSON
        output_file = Path(model_path).parent / 'model_metadata.json'
        
        # Preparar diccionario con metadata para guardar
        metadata = {}
        for key in ['epoch', 'best_fitness', 'train_args', 'date', 'version', 'updates']:
            if key in checkpoint:
                metadata[key] = checkpoint[key]
        
        # Convertir valores no serializables
        def convert_for_json(obj):
            if hasattr(obj, 'item'):  # Para tensors de pytorch
                return obj.item()
            elif isinstance(obj, dict):
                return {k: convert_for_json(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_for_json(item) for item in obj]
            else:
                return obj
        
        metadata = convert_for_json(metadata)
        
        with open(output_file, 'w') as f:
            json.dump(metadata, f, indent=2, default=str)
        
        print(f"\nüíæ METADATA GUARDADA EN:")
        print("-" * 30)
        print(f"  üìÑ {output_file}")
        
        print(f"\n" + "="*80)
        print(f"üéØ RESUMEN PRINCIPAL:")
        print(f"="*80)
        
        # Analizar el archivo CSV para encontrar el epoch real
        epoch_from_model = checkpoint.get('epoch', 'N/A')
        print(f"üèÜ EPOCH EN EL MODELO: {epoch_from_model} (no confiable)")
        
        # Buscar el epoch real en el CSV
        if results_file.exists():
            try:
                with open(results_file, 'r') as f:
                    lines = f.readlines()
                    if len(lines) > 1:
                        # La √∫ltima l√≠nea v√°lida es el √∫ltimo epoch entrenado
                        last_line = lines[-1].strip()
                        if last_line:
                            epoch_real = last_line.split(',')[0]
                            print(f"üéØ EPOCH REAL (del CSV): {epoch_real}")
                            print(f"üìä TOTAL DE EPOCHS ENTRENADOS: {len(lines) - 1}")
                        
                        # Analizar para encontrar el mejor epoch
                        print(f"\nüîç ANALIZANDO EL MEJOR EPOCH...")
                        header = lines[0].strip().split(',')
                        
                        # Buscar columnas de m√©tricas importantes
                        fitness_cols = []
                        for i, col in enumerate(header):
                            if 'fitness' in col.lower() or 'map' in col.lower() or 'precision' in col.lower():
                                fitness_cols.append((i, col))
                        
                        if fitness_cols:
                            print(f"üìà M√©tricas encontradas: {[col[1] for col in fitness_cols]}")
                            
                            # Analizar l√≠neas para encontrar mejores valores
                            best_epochs = {}
                            for line_num, line in enumerate(lines[1:], 1):  # Skip header
                                values = line.strip().split(',')
                                if len(values) > max(col[0] for col in fitness_cols):
                                    for col_idx, col_name in fitness_cols:
                                        try:
                                            value = float(values[col_idx])
                                            if col_name not in best_epochs or value > best_epochs[col_name][1]:
                                                best_epochs[col_name] = (line_num, value)
                                        except:
                                            continue
                            
                            for metric, (best_epoch, best_value) in best_epochs.items():
                                print(f"  üèÖ Mejor {metric}: Epoch {best_epoch} (valor: {best_value:.4f})")
                        
            except Exception as e:
                print(f"‚ö†Ô∏è Error analizando CSV: {e}")
        
        # Mostrar fitness del modelo (con manejo seguro de None)
        best_fitness = checkpoint.get('best_fitness')
        if best_fitness is not None:
            print(f"üèÖ FITNESS DEL MODELO: {best_fitness:.6f}")
        else:
            print(f"üèÖ FITNESS DEL MODELO: No disponible (None)")
            
        print(f"üìÅ MODELO UBICADO EN: {model_path}")
        print(f"‚úÖ EXTRACCI√ìN DE METADATA COMPLETADA")
        
    except Exception as e:
        print(f"‚ùå Error extrayendo metadata: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    extract_model_metadata()
